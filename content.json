{"meta":{"title":"SevenHsu","subtitle":null,"description":null,"author":"Seven Hsu","url":"https://sevenhsu.github.io"},"pages":[],"posts":[{"title":"MTCNN(人脸检测)","slug":"2019_06_07_22","date":"2019-09-05T09:23:07.064Z","updated":"2019-09-05T09:23:07.064Z","comments":true,"path":"2019/09/05/2019_06_07_22/","link":"","permalink":"https://sevenhsu.github.io/2019/09/05/2019_06_07_22/","excerpt":"","text":"MathJax.Hub.Config({tex2jax:{inlineMath:[['$','$'],['\\\\(','\\\\)']]}}); 1 基本描述 概述：MTCNN是一个多任务的及联卷积网络，用于人脸检测和矫正，是属于anchor free的一类检测算法。训练时，分别训练三个网络；预测时，通过图像金字塔的方式检测多个尺寸的人脸。网络完成了人脸检测和关键点回归两个任务，关键点可以用于人脸矫正。所以MTCNN是将人脸检测和人脸矫正放在了一起。 原始论文： Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks 论文复现：MTCNN-TensorFlow 2 网络结构 首先了解MTCNN的网络结构才能理解MTCNN的工作原理及优缺点，作者使用三个网络网络及联起来实现人脸检测和关键点标定两个任务，可有有效的提高检测的效果，提高mAP。三个网络的作用都是一样的，用于人脸检测和关键点回归；唯一的区别在于三个网络的输入尺寸是不同的和第一个网络(P-Net)是全卷积，下面将会细讲三个网络。 图2.1 MTCNN网络结构 2.1 P-Net(Proposal) P-Net是MTCNN的第一个网络，是一个全卷积网络。P-Net的目的是初步筛选出可能的人脸区域，即起到Proposal（预选）的作用。图2.1中P-Net的输入是$12\\times12\\times3$,实则只有在训练的时候我们明确的给定网络的输入为$12\\times12\\times3$的图片。在预测的时候输入是任意尺寸的图像，具体细节在实现过程中讲解。 图2.2 P-Net网络结构 从网络结构可以看出P-Net的感受野是$12\\times12$，所以在训练的时候我们输入$12\\times12\\times3$的图像训练，经过三层网络（第一层卷积后接了一个max pool）后得到32个$1\\times1$的feature map。再接三个$1\\times1$的卷积网络，分别用于分类、回归人脸位置和回归5个关键点。在预测的时候我们将一张图像resize到不同的尺寸得到图像金字塔，然后依次将每个尺寸的图像输入P-Net得到每个尺寸图片的检测结果。 图2.3 图像金字塔 训练时输入的图像是$12\\times12\\times3$的，可以很好的理解为这张$12\\times12$的图像是不是人脸，并且回归人脸位置和关键点位置。那么预测时输入是任意尺寸的图像，这时是如何预测整张图像的全部位置是否是人脸，以及回归人脸位置和关键点的？ 图2.4 检测过程 960x640的图像先做Resize生成图像金字塔，这里取其中一张结果$672\\times448$。将$672\\times448$的图像输入P-Net得到$332\\times219$的feature map，此时feature map第一个像素就对应着输入图像中第一个$12\\times12$像素区域的feature map（也就对应着原图中第一个$17\\times17$像素的区域）。就跟将输入图像中第一个$12\\times12$的像素抠出来输入P-Net一样，起到了滑动窗口的作用，但只是做了卷积。当然P-Net所用到的只是$12\\times12$像素区域，也就是说能包含的信息非常少，只能做一个大概的判断是否是人脸和回归一个大概的人脸位置。因此，在P-Net中可以不做关键点的回归。所以预测时，图像通过P-Net会有许多误检。预测时可以通过非极大值抑制（NMS）”合并”重合率较高的检测框，亦可以通过confidence筛选检测框。 2.2 R-Net(Refinement) R-Net，故名思意，就是一个精炼的网络，将P-Net筛选出的可能人脸区域输入给R-Net中，做进一步的筛选。 图2.5 R-Net网络结构 由于R-Net不是全卷积网络，因此R-Net的输入时固定的，为$24\\times24$。在训练和预测时，都需要将图像Resize到$24\\times24$的大小。R-Net的输入是$24\\times24$，比P-Net多上4倍的信息，也就使得R-Net的分类和回归效果要好于P-Net。因此，在R-Net中就可以对人脸关键点进行训练。预测时，P-Net筛选出的人脸区域将在R-Net中被进一步过滤，人脸的位置也将被再一次的回归。 2.3 O-Net(Output) O-Net，作者称之为输出网络，大概是因为这是最后一个网络了吧，该在这里结束输出了。O-Net和R-Net没有本质上的区别，都是在进一步地筛选人脸及回归位置和关键点。 图2.5 O-Net网络结构 O-Net和R-Net一样，对上一个网络筛选的结果做进一步过滤和position的回归。为了能够更好的学到人脸的特征，作者将O-Net加深了一层，也将O-Net的输入调到了$48\\times48$。最终的输出就是人脸的位置(x1,y1,x2,y2)和5个关键点的坐标，一共14个输出值。当然不是人脸的就不需要输出了。 3 实现过程 MTCNN一共三个网络，每个网络的输入都不一样。所以需要训练数据做需处理。对于P-Net，输入是$12\\times12$。对于R-Net，输入是$24\\times24$。对于O-Net，输入是$48\\times48$。三个网络最后都有三个分支，分别是人脸二分类（是否人脸）、人脸位置回归、关键点回归。 3.1 数据处理 对于训练数据，只有图片和标注的人脸框坐标。为了能够更好的训练网络，使其能够在分类和回归上都有非常好的表现，需要我们手动生成我们的训练样本。对于分类任务，需要的是人脸正样本和非人脸负样本。对于回归人脸位置坐标点任务，需要人脸正样本和部分人脸样本。 图3.1 正样本(人脸) 在分类时，需要人脸正样本。我们可以在原始数据集GT的四周随机取矩形框，并计算其与GT的IoU值，取IoU大于0.6的为正样本。 图3.2 负样本(非人脸) 同样取与GT的IoU小于0.3的矩形框区域为负样本。 图3.3 部分人脸样本(部分人脸) 为了更好的回归人脸关键点位置，需要部分人脸样本。所以在GT周围随机取矩形框，选取其中与GT的IoU介于0.3和0.6之间的矩形框区域为部分人脸样本。回归人脸位置坐标需要注意的是，这里直接回归四个坐标值是困难的。所以在实际训练的时候，我们回归其与GT的偏差。 $$d_x=\\frac{GT_x-x}{size}$$ $$d_y=\\frac{GT_y-y}{size}$$ 计算随机取的部分人脸矩形框和GT的偏差，上式中GT_x表示GT中横坐标点的值，x表示随机选取的部分人脸框的横坐标值。size是随机挑选取的矩形框的尺寸。正样本也需要计算其偏差。 对于人脸关键点数据准备，不必多讲。利用标注在人脸上的五个关键点数据训练并回归即可。 准备好上面四种数据，并生成四种数据的label（格式如下） 1234positive sample:image_name 1 dx1 dy1 dx2 dy2negative sample:image_name 0partial sample:image_name -1 dx1 dy1 dx2 dy2landmark sample: x1 y1 x2 y2 x3 y3 x4 y4 x5 y5 MTCNN的三个网络在训练时，主要作用略有偏差。所有针对每个网络，数据的比列有所不同，论文中使用的比例是$neg:pos:part:landmark=3:1:1:2$。 3.2 Loss函数 MTCNN中每个网络都有三个任务。人脸二分类，损失函数是交叉熵损失函数；人脸位置坐标回归，是L2损失函数；最后是人脸关键点(MTCNN中为5个关键点)回归，也是L2损失函数。 人脸检测的交叉熵损失函数： $$L_i^{det}=-(y_i^{det}log(p_i)+(1-y_i^{det})(1-log(p_i)))$$人脸坐标位置回归损失函数(L2)： $$L_i^{box}=\\left |\\left |\\hat y_i^{box}-y_i^{box}\\right |\\right |_2^2$$landmark关键点回归损失函数(L2) $$L_i^{landmark}=\\left |\\left|\\hat y_i^{landmark}-y_i^{landmark}\\right |\\right|_2^2$$针对PNet,RNet,ONet三个网络,每个网络都有三个任务的损失函数。所以最终的目的是最小化最终的损失函数（对二分类、坐标点回归、landmark回归三部分的损失函数的加权求和）。 $$min\\sum_{i=1}^N\\sum_{j\\in{det,box,landmark}}\\alpha_j\\beta_i^jL_i^j$$上式中，N是训练样本数，$\\alpha_j$表示针对三个任务的权重，$\\alpha_j$在PNet、RNet、ONet中的取值不相同，因为三个网络对三种任务的侧重点不一样。PNet和RNet中$\\alpha_{det}=1$,$\\alpha_{box}=0.5$,$\\alpha_{landmark}=0.5$;ONet中$\\alpha_{det}=1$,$\\alpha_{box}=0.5$,$\\alpha_{landmark}=1$;$\\beta_i^j\\in\\{0,1\\}$表示样本类型标识，如果样本类别是正负样本，就只需要计算$L_{det}$,所以设置$\\beta_i^{box}$和$\\beta_i^{landmark}$为0。 3.3 训练 训练的时候需要训练分别训练PNet、RNet、ONet三个网络，针对PNet的任务初步是筛选可能的人脸区域，确定出后选框。针对RNet是近一步筛选出人脸区域，并对人脸位置做回归矫正。以及对人脸关键点的回归。ONet和RNet的任务终点一致，仍然需要进一步筛选高质量的人脸区域和精确回归人脸坐标位置以及修正人脸五个关键点的位置。在训练过程中，每一个mini-batch包含多种样本类型，所以针对样本类型不同，计算的loss也就不同，需要注意$\\beta_i^j$。 3.3.1 OHEM（Online Hard example mining） 在MTCNN训练过程中作者还提出了一个trick，就是在线困难样本挖掘，其目的是在训练网络的过程中实时的挑选出困难样本，以使得模型有更好的收敛效果。当然作者也通过实验证明了OHEM确实使得模型有更好的表现。如何实现OHEM呢？在训练过程中，将前向传播过程中计算得到的loss排序。然后选出loss排前70%的样本，在反向传播过程中只需要计算这前70%的样本的loss。 3.3.2 训练PNetPNet的训练需要大量的正负样本用于训练好一个分类器，这时候的部分人脸样本就不需要太多，在PNet中可以不做landmark的训练。需要注意的是在训练的时候PNet的输入是$12\\times$的图片，而不是任意大小的图片。在第三层卷积之后并行接两个$1\\times1$的卷积得到分类结果和位置坐标点，然后计算联合loss。在计算联合loss的时候记得乘以每个loss的权重。 3.3.3 训练RNet训练RNet，主要是进一步在PNet的结果上筛选质量更高的人脸。所以在这一步，网络的输入调整至$24\\times24$,并在这一步训练人脸关键点的回归。所以训练RNet时需要用到正负样本、部分人脸样本和landmark数据样本。 3.3.4 训练ONetONet的训练和RNet的训练没有区别，仅仅只是输入上的尺寸调整为$48\\times48$，目的是在第三个输出网络上，得到更好的结果，就需要更多的信息用于人脸的精选和坐标位置的精确回归。 3.4 预测 预测也是分三步。不过在第一步开始之前，需要对输入图片做一下处理。即生成图像金字塔，由于PNet是全卷积，没有固定的输入尺寸，而针对每张图像的感受野是$12\\times12$，所以需要生成图像金字塔，以便检测出图像中所有尺寸的人脸。第一，通过PNet确定每个中心点的得分和位置坐标，通过NMS(non-maximum suppression，非极大值抑制)的方法和设置PNet的score 阈值筛掉一部分区域。第二，将第一步由PNet得到的区域(此区域通过位置坐标点抠出来)resize到$24\\times24$的尺寸然后输入到RNet中，通过RNet得到每个区域的得分和坐标点回归值以及landmark的回归点。再次通过NMS和RNet设置的阈值过滤掉一部分人脸。第三，将RNet筛选出的区域（位置坐标点已更新，区域已调整）抠出来，resize到$48*48$的尺寸输入ONet，通过ONet得到face score，face position和landmark position，最后再次通过NMS和ONet的阈值筛选出最终的人脸。 3.4.1 生成图像金字塔针对预测时输入的每张图像，根据一定的比例循环resize图像，直到图像尺寸小于我们希望检测到最小人脸尺寸。1234567img //输入图像scale = size of imgfactor //缩放比例img_list //图像金字塔列表while scale &gt; min_face_size add resize(img,scale) to img_list scale = scale * factor 然后通过三个网络得到最终的结果，高质量的人脸face和精准的face position以及精准的landmark结果。最后使用landmark结果做仿射变换实现人脸矫正，得到最终结果。 4 总结MTCNN是一个anchor free的方法，整个网络结构非常简单，但是这种级联网络的方式非常好。三个网络逐级检测使得检测的质量明显提高，其次在前一级网络筛掉大量非人脸区域后，使得后面的网络的计算量笑了许多。而且将；landmark结合到face classify 和 face position regression中也使得MTCNN的功能非常强大。但是MTCNN在预测时需要做图像金字塔，这明显会使得PNet以及后面网络的计算量提高。 5 参考资料MTCNN)MTCNN MATLAB implementation","categories":[{"name":"CV","slug":"CV","permalink":"https://sevenhsu.github.io/categories/CV/"}],"tags":[{"name":"CV","slug":"CV","permalink":"https://sevenhsu.github.io/tags/CV/"},{"name":"Face Detect","slug":"Face-Detect","permalink":"https://sevenhsu.github.io/tags/Face-Detect/"}],"keywords":[{"name":"CV","slug":"CV","permalink":"https://sevenhsu.github.io/categories/CV/"}]},{"title":"ResNet","slug":"2019_03_19_10","date":"2019-09-03T12:30:37.387Z","updated":"2019-09-03T12:30:37.387Z","comments":true,"path":"2019/09/03/2019_03_19_10/","link":"","permalink":"https://sevenhsu.github.io/2019/09/03/2019_03_19_10/","excerpt":"","text":"MathJax.Hub.Config({tex2jax:{inlineMath:[['$','$'],['\\\\(','\\\\)']]}}); 1 基本描述 原始论文： Deep Residual Learning for Image Recognition 论文复现：ResNet-TensorFlow 2 背景问题 ResNet的提出是为了解决深层网络难训练的问题 CNN在图像特征提取方面有非常好的拓展性，增加网络深度可以提取更多的特征，越深的层 提取的特征越抽象，越具有语义信息。 直接增加网络的层数会导致梯度消失或梯度爆炸等问题是的模型训练失败。 在模型中增加正则化和在模型中间增加BN(batch normalization)可避免梯度消失和梯度爆炸等问题，使得模型可训练。 虽然增加正则和BN层的模型可训练，但是深层模型在训练时出现了收敛退化的问题，ResNet作者通过实验证明通过多次迭代训练是无法解决对话问题的。 3 网络结构 作者为了解决深层网络难以训练的问题，提出了残差学习，在深层的训练的时候，将输入的feature map加上浅层的feature map特征。ResNet的网络结构借鉴了VGG的网络结构，在第一层使用了7*7的大尺寸卷积核，在后面的卷积block中都使用了细小的卷积核。 3.1 残差函数 图3.1 残差学习block 残差函数 $$H(x)=F(x)+x$$ F(x)可以用前向传播shortcut connection(shortcut connection)。shortcut connection就是如图所示跳过一层或多层的连接，在resnet中这个shortcut connection是简单的将恒等mapping加上当前层的输出。恒等的shortcut connection即没有增加额外的参数也没有增加计算复杂度，所以整个网络依然是可以端到端训练的。 3.2 shortcut connection ResNet文章中作者提出shortcut connection的方式有三种 A：zero-padding，没有额外的参数。在mapping的四周填充0 B：使用1*1的卷积投影增加shortcut维度，不需要改变尺寸和维度的恒等不变 C：全部shortcut使用1*1的卷积投影 A、B、C三种方式的优缺点主要体现在时间复杂度上，A的参数量 &lt; B的参数量 &lt; C的参数量。由于C对全部的shortcut都使用了1*1的卷积投影，导致训练时间上近乎是B的两倍。作者通过实验分析得到C的效果略微优于A和B，这是优于C在1*1的卷积上也学到了一些特征 3.3 bottleneck 考虑到更深的网络能够承受的训练时长，作者对深层网络将block改成了Bottleneck的设计对于残差函数F(x) ，使用堆叠的3层卷积网络替换block的2层，3层分别是1*1，3*3，1*1。其中的1*1的卷积是负责消减和扩展维度的。 non-Bottleneck和Bottleneck 图3.2 non-bottleneck和bottleneck结构 图3.2左侧的是non-Bottleneck结构，shortcut connection跳过的是两个3*3的卷积。右侧是bottleneck的结构。 多层ResNet结构 表3.1 在ImageNet分类任务上的网络结构 表3.1是基于ImageNet分类任务的ResNet网络结构，输入是224*224放入图片。 图3.3 VGG19/普通深层网络/ResNet深层网络对比 右侧是34层的ResNet网络结构图，图中的实线恒等连接，虚线是需要做维度变换的，用到的方法就是上面的A、B、C三种。 4 实现工作4.1 数据预处理ResNet在实验上对图片的处理借鉴了VGG的方法，将图片缩放到[256,480]之间的随机尺寸，然后在缩放的图片之间随机裁剪尺寸为224*224的图片，这样也起到了数据增强的作用。在测试和预测的时候可以采用同样的方式随机裁剪多张图片，取预测结果的众数。 网络搭建在卷积层之后添加BN层可以防止过拟合，每一个卷积block开始训练前保存输入，在block训练后做shortcut connection，在连接的时候考虑feature map和保存的输入维度是否一致，不一致使用上文的A、B、C三种方法做放缩。 4.2 在CIFAR-10的实验分析 数据预处理，网络的输入是32*32,每个像素减去平均值。第一层是3*3的卷积,然后一共使用堆叠6n层3*3的卷积，feature map size分别为{32,16,8},每个feature map size堆叠2n层。卷积核的数量是{16,32,64},作者在实验中测试了n={3,5,7,9}，结果error大概在7左右。 5 总结总体上来说ResNet的网络结构并不复杂，但是提出残差学习这点，并且使得深层网络可训练简直是一次技术上的革命。ResNet基础网络大部分借鉴了VGG，其中的first convolution和后面block里的3*3的细小卷积核和使用随机裁剪的图像处理方法。ResNet的重点在于残差学习，这使得训练的深层网络在ImageNet等比赛中取得了冠军。 参考资料 ResNet 残差网络ResNet笔记","categories":[{"name":"CV","slug":"CV","permalink":"https://sevenhsu.github.io/categories/CV/"}],"tags":[{"name":"tensorflow","slug":"tensorflow","permalink":"https://sevenhsu.github.io/tags/tensorflow/"},{"name":"python","slug":"python","permalink":"https://sevenhsu.github.io/tags/python/"}],"keywords":[{"name":"CV","slug":"CV","permalink":"https://sevenhsu.github.io/categories/CV/"}]},{"title":"linux开启ssh服务","slug":"2019_03_28_18","date":"2019-06-12T15:28:11.953Z","updated":"2019-06-12T15:28:11.953Z","comments":true,"path":"2019/06/12/2019_03_28_18/","link":"","permalink":"https://sevenhsu.github.io/2019/06/12/2019_03_28_18/","excerpt":"","text":"1 基本描述 在自己的linux服务器上配置ssh服务器，添加新用户并通过ssh连接服务器 2 安装ssh服务并配置 通过命令service sshd status查看ssh服务器状态，如果自己的服务器上已经安装了ssh服务器，则跳过此步骤 通过以下命令安装ssh服务器 123sudo apt-get install openssh-server#或者使用yum 安装sudo yum install openssh-server 编辑/etc/ssh/sshd_config文件配置ssh 12PermitRootLogin yes # 是否允许root通过ssh认证PasswordAuthentication no # 是否允许使用密码认证 3 添加用户并配置用户的ssh认证 通过以下命令添加新用户，根据自己的需要配置参数 添加新用户的命令 123456useradd [-d home] [-s shell] [-c comment] [-m] [-r] name# -d /home/username：设置用户登入时的主目录# -s /bin/bash：用户登入时使用的shell# -c comment：备注# -m 用户目录不存在时，自动建立用户的登入目录# -r 建立系统账号 提升用户权限 将用户提升到sudoers权限，编辑/etc/sudoers 123sudo vim /etc/sudoers# 配置如下：在root ALL=(ALL:ALL) ALL下添加一行username ALL=(ALL) ALL 用户在本地生成自己的ssh密钥对 安装git，使用git bash下执行ssh-keygen -t rsa -C &quot;youremail@example.com&quot;生成自己的密钥对生成的密钥对位置：Windows在C:/Users/username/.ssh,Mac os在/home/username/.ssh 将自己.ssh/id_rsa.pub的内容复制到服务器/home/username/.ssh/authorized_keys文件里。其中username为新建用户的名字，/home/username/.ssh/authorized_keys路径不存在就自己建立文件夹和文件。 新建.ssh文件夹和authorized_keys文件 12sudo mkdir .ssh # 建立.ssh文件夹sudo vim authorized_keys # 将自己的公钥(id_rsa.pub)内容写进去 配置文件和文件夹权限 123sudo chmod 600 /home/username/.ssh/authorized_keys # 设置authorized_keys的权限为600sudo chmod 700 /home/username/.ssh # 设置.ssh的权限为700sudo chown -R username. /home/username # 设置username文件夹的拥有者为username 配置好一切后，用户在本地终端使用ssh serverhost即可连接到服务器。","categories":[{"name":"Other","slug":"Other","permalink":"https://sevenhsu.github.io/categories/Other/"}],"tags":[{"name":"ssh","slug":"ssh","permalink":"https://sevenhsu.github.io/tags/ssh/"},{"name":"linux","slug":"linux","permalink":"https://sevenhsu.github.io/tags/linux/"}],"keywords":[{"name":"Other","slug":"Other","permalink":"https://sevenhsu.github.io/categories/Other/"}]},{"title":"Deep-Head-Pose(头部姿态)","slug":"2019_05_21_15","date":"2019-06-08T03:00:01.681Z","updated":"2019-06-08T03:00:01.682Z","comments":true,"path":"2019/06/08/2019_05_21_15/","link":"","permalink":"https://sevenhsu.github.io/2019/06/08/2019_05_21_15/","excerpt":"","text":"1 基本描述 概述：通过卷积网络学习图像特征，做到头部姿态预测 2 网络结构3 实现过程4 训练&amp;预测5 总结","categories":[{"name":"CV","slug":"CV","permalink":"https://sevenhsu.github.io/categories/CV/"}],"tags":[{"name":"CV","slug":"CV","permalink":"https://sevenhsu.github.io/tags/CV/"},{"name":"Head Pose","slug":"Head-Pose","permalink":"https://sevenhsu.github.io/tags/Head-Pose/"}],"keywords":[{"name":"CV","slug":"CV","permalink":"https://sevenhsu.github.io/categories/CV/"}]},{"title":"如何在服务器上使用Tensorboard","slug":"2019_03_09_14","date":"2019-03-19T08:44:39.777Z","updated":"2019-03-19T08:44:39.777Z","comments":true,"path":"2019/03/19/2019_03_09_14/","link":"","permalink":"https://sevenhsu.github.io/2019/03/19/2019_03_09_14/","excerpt":"","text":"方法一 在服务器上启动Tensorboard，保证本地主机能够正常访问服务器下，在本地访问服务器IP:Tensorboard所在端口 服务器上启动Tensorboard 12tensorboard --logdir your_logdir_path --port 8000# your_logdir_path:你的tensorflow训练日志文件夹 本地浏览器访问 比如服务器IP为10.0.1.12,在本地浏览器访问10.0.1.12:8000就可以了。 方法二 在服务器上启动Tensorboard，将服务器端口映射到本地主机上，在本地访问localhost:映射的端口 内网映射： 12345ssh -L local_port:127.0.0.1:server_port username@server_ip# local_port:映射到本地的端口号# server_port:服务器的映射端口号# username:访问服务器的用户名# server_ip:服务器IP 外网映射 123456ssh -p telnet_port -L local_port:127.0.0.1:server_port username@server_ip# telnet_port:远程连接端口# local_port:映射到本地的端口号# server_port:服务器的映射端口号# username:访问服务器的用户名# server_ip:服务器IP 服务器上启动Tensorboard 1tensorboard --logdir your_logdir_path --port server_port 本地浏览器访问 本地浏览器访问127.0.0.1:local_port","categories":[{"name":"Other","slug":"Other","permalink":"https://sevenhsu.github.io/categories/Other/"}],"tags":[{"name":"tensorflow","slug":"tensorflow","permalink":"https://sevenhsu.github.io/tags/tensorflow/"}],"keywords":[{"name":"Other","slug":"Other","permalink":"https://sevenhsu.github.io/categories/Other/"}]},{"title":"github+hexo搭建个人博客","slug":"2019_03_09_16","date":"2019-03-09T15:44:07.509Z","updated":"2019-03-09T15:44:07.509Z","comments":true,"path":"2019/03/09/2019_03_09_16/","link":"","permalink":"https://sevenhsu.github.io/2019/03/09/2019_03_09_16/","excerpt":"","text":"1 基本描述 项目存储：使用Github来存放个人博客项目,并使用Github的pages服务使个人博客能够被浏览器访问(http请求)。 项目创建：使用node.js的npm下载安装Hexo,使用Hexo生成博客项目 项目管理：使用git管理项目版本和推送项目到Github 博客评论：使用gittalk实现博客留言 访问统计：使用腾讯分析提供的接口统计博客的访问量和访客数 2 所需资源 Github:面向开源及私有软件项目的托管平台，供存放博客项目。需注册自己的账号 git一个开源的分布式版本控制系统,用于管理项目版本和将本地代码推送至Github平台，需下载安装 Node.js:一个让 JavaScript 运行在服务端的开发平台,需要下载并安装在本机 NPM:(node.js package manager)是随同NodeJS一起安装的包管理工具，可用于下载第三方包，能解决NodeJS代码部署上的很多问题，无需单独下载安装 Hexo:一款使用node.js开发的简单、极速、强大的博客框架，用于快速生成的博客 Gittalk一个基于 GitHub Issue 和 Preact 开发的评论插件,需在支持Gittalk的主题中配置相关信息，也可在不支持的主题中增加Gittalk插件 腾讯分析用于统计访问量和访客数，需注册并添加自己博客的站点 3 资源准备3.1 下载安装git 点击这里下载对应版本git并安装 安装git后生成自己的ssh密钥对，用于github的认证。在终端(Mac os/Linux)或者cmd(Windows)执行以下命令生成ssh密钥 123ssh-keygen -t rsa -C \"youremail@example.com\"# -t:指定密钥类型，默认rsa# -C:指定注释，用于标示密钥，内容任意 3.2 下载安装node.js 点击这里下载对应版本node.js 3.3 下载安装Hexo 安装node.js后在终端(Mac os/Linux)或者cmd(Windows)执行以下命令安装Hexo 1npm install hexo-cli -g 4 博客搭建4.1 注册Github平台账号并创建博客项目仓库4.1.1 注册Github 点击这里到注册页面进行注册 注册完成后，将个人本地的ssh公钥添加到自己Github账号中。打开.ssh-&gt;id_rsa.pub(.shh文件夹在不同系统存放路径不一致) 在个人Github账号Settings-&gt;SSH and GPG keys下新建SSH key，复制id_rsa.pub文件中内容粘贴到key中 4.1.2 创建博客项目仓库 登录到Github，并创建个人博客仓库(标记为：远程仓库) 新建仓库，填写仓库名和描述。仓库名须为github_name.github.io的形式，其中github_name为个人github账户名 仓库创建完成后，需要将github上的仓库克隆到本地，复制你的仓库ssh地址 在终端或cmd下进入想克隆的路径下使用以下命令克隆,请记住这个文件夹(标记为：本地仓库)的位置 1git clone git@github.com:github_name/guthub_name.github.io.git 4.2 生成本地博客项目并推送至远程仓库 使用Hexo生成博客项目，最后将博客项目文件夹内的所有文件&amp;文件夹拷贝至本地仓库 4.2.1 生成博客项目 在终端或cmd下进入想存放的路径，执行以下命令即可完成博客项目(博客网站)的生成 123hexo init &lt;folder&gt;cd &lt;folder&gt;npm install 4.2.2 本地预览博客 在将博客项目内的所有文件&amp;文件夹拷贝至本地仓库后，在终端或cmd下进入本地仓库根目录下执行以下命令启动博客的http服务。然后在浏览器中访问localhost:4000 1hexo server 4.2.3 推送博客项目至远程仓库 打开本地仓库根目录下的_config.yml文件，在文件的最后配置部署信息 完成部署配置后，在终端或cmd下进入本地仓库根目录下执行以下命令将本地仓库推送到远程仓库。然后访问http://github_name.github.io 即可访问远程仓库上的博客 123hexo clean # 清除缓存hexo generate # 生成静态文件hexo deploy # 部署到远程仓库 5 评论插件 使用Gittalk插件将评论存放在指定的仓库下,获取用于认证存放评论的Client ID 和 Client Secret 5.1 注册Github APP 在个人Github-&gt;Settings-&gt;Developer Settings下新建一个OAuth App并获取Client ID和Client Secret。此处红框中需要填写你的博客地址https://github_name.github.io 下面是Client ID和Client Secret 5.2 配置Gittalk插件 打开本地仓库根目录-&gt;themes-&gt;(theme_folder)-&gt;_config.yml配置Gittalk，其中Client ID 和 Client Secret是前面得到的，repo是存放评论的仓库名，owner是仓库的所有者，admin是仓库的管理者 5.3 初始化评论 由于评论存储在github仓库issue中，没有任何文章的信息，所以需要先对每个文章初始化一个评论，后续的评论将会依附在初始评论下 5.3.1 获取初始化评论的token 点击这里创建access token用于初始化认证,选中红框内的条目，描述随意填写 复制你的access token，之后将不在显示 5.3.2 添加自动初始化脚本 在本地仓库根目录下新建comment.js文件，将以下js代码粘贴到comment.js文件中，脚本将会在部署的时候自动初始化评论。请注意替换脚本中的帐户信息 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110const request = require(\"request\");const fs = require(\"fs\");const path = require(\"path\");const url = require(\"url\");const xmlParser = require(\"xml-parser\");const YAML = require(\"yamljs\");const cheerio = require(\"cheerio\");// 根据自己的情况进行配置const config = &#123; username: \"github_name\", // GitHub 用户名 token: \"824c5d68b801b4255f0738cb91e0f893c443739f\", // GitHub Token repo: \"github_name.github.io\", // 存放 issues的git仓库 // sitemap.xml的路径，commit.js放置在根目录下，无需修改，其他情况自行处理 sitemapUrl: path.resolve(__dirname, \"./public/sitemap.xml\"), kind: \"Gitalk\", // \"Gitalk\" or \"Gitment\"&#125;;let issuesUrl = `https://api.github.com/repos/$&#123;config.username&#125;/$&#123;config.repo&#125;/issues?access_token=$&#123;config.token&#125;`;let requestGetOpt = &#123; url: `$&#123;issuesUrl&#125;&amp;page=1&amp;per_page=1000`, json: true, headers: &#123; \"User-Agent\": \"github-user\" &#125;&#125;;let requestPostOpt = &#123; ...requestGetOpt, url:issuesUrl, method: \"POST\", form: \"\"&#125;;console.log(\"开始初始化评论...\");(async function() &#123; console.log(\"开始检索链接，请稍等...\"); try &#123; let websiteConfig = YAML.parse(fs.readFileSync(path.resolve(__dirname, \"./_config.yml\"), \"utf8\")); let urls = sitemapXmlReader(config.sitemapUrl); console.log(`共检索到$&#123;urls.length&#125;个链接`); console.log(\"开始获取已经初始化的issues:\"); let issues = await send(requestGetOpt); console.log(`已经存在$&#123;issues.length&#125;个issues`); let notInitIssueLinks = urls.filter((link) =&gt; &#123; return !issues.find((item) =&gt; &#123; link = removeProtocol(link); return item.body.includes(link); &#125;); &#125;); if (notInitIssueLinks.length &gt; 0) &#123; console.log(`本次有$&#123;notInitIssueLinks.length&#125;个链接需要初始化issue：`); console.log(notInitIssueLinks); console.log(\"开始提交初始化请求, 大约需要40秒...\"); /** * 部署好网站后，直接执行start，新增文章并不会生成评论 * 经测试，最少需要等待40秒，才可以正确生成， 怀疑跟github的api有关系，没有找到实锤 */ setTimeout(async ()=&gt;&#123; let initRet = await notInitIssueLinks.map(async (item) =&gt; &#123; let html = await send(&#123; ...requestGetOpt, url: item &#125;); let title = cheerio.load(html)(\"title\").text(); let pathLabel = url.parse(item).path; let body = `$&#123;item&#125;&lt;br&gt;&lt;br&gt;$&#123;websiteConfig.description&#125;`; let form = JSON.stringify(&#123; body, labels: [config.kind, pathLabel], title &#125;); return send(&#123; ...requestPostOpt, form &#125;); &#125;); console.log(`已完成$&#123;initRet.length&#125;个！`); console.log(\"可以愉快的发表评论了！\"); &#125;,40000); &#125; else &#123; console.log(\"本次发布无新增页面，无需初始化issue!!\"); &#125; &#125; catch (e) &#123; console.log(`初始化issue出错，错误如下：`); console.log(e); &#125; finally &#123; &#125;&#125;)();function sitemapXmlReader(file) &#123; let data = fs.readFileSync(file, \"utf8\"); let sitemap = xmlParser(data); return sitemap.root.children.map(function (url) &#123; let loc = url.children.filter(function (item) &#123; return item.name === \"loc\"; &#125;)[0]; return loc.content; &#125;);&#125;function removeProtocol(url) &#123; return url.substr(url.indexOf(\":\"));&#125;function send(options) &#123; return new Promise(function (resolve, reject) &#123; request(options, function (error, response, body) &#123; if (!error) &#123; resolve(body); &#125; else &#123; reject(error); &#125; &#125;); &#125;);&#125; 5.3.3 一行命令部署 在终端或cmd进入本地仓库根目录下，执行之前部署到远程的命令加上初始化评论的命令即可将可评论的新版本推送到线上 跳过，直接一行命令部署 1234hexo clean # 清除缓存hexo generate # 生成静态文件hexo deploy # 部署到远程仓库node ./comment.js # 初始化评论 首先将上面的多行命令按json的格式添加到本地仓库根目录下的package.json文件末尾 多行命令的json格式 1234\"scripts\": &#123; \"deploy\": \"hexo clean &amp;&amp; hexo generate &amp;&amp; hexo deploy &amp;&amp; node ./comment.js\" &#125; 一行命令部署,后续博客的修改、文章的发布后只需要执行这一行命令即可更新发布到远程仓库 1npm run deploy 6 访问量统计 点击这里注册腾讯分析账号，在个人-&gt;站点列表中添加站点(博客地址) 然后将站点统计的ID放到博客所用的主题下的_config.yml文件对应的腾讯统计下，也可以自己将统计的代码放到博客网页中 1&lt;script type=\"text/javascript\" src=\"https://tajs.qq.com/stats?sId=ID\" charset=\"UTF-8\"&gt;&lt;/script&gt; 7 更换主题和更新文章7.1 更换主题 可在Hexo官网下载自己感兴趣的主题 将主题文件夹放在本地仓库根目录下的themes文件夹下 修改本地仓库根目录下的_config.yml文件中的themes 7.2 更新文章 只需将新的markdown类型的文章放置在本地仓库根目录下的sources-&gt;_posts文件夹下即可 须注意在文章开头要标明文章标题、所属分类、以及标签。格式如下 12345678---title: HelloWorldtags: - hello - blogcategories: - Other--- 8 注意事项 文章的github_name为自己的Github用户名 博客根目录和主题文件夹下都存在source文件夹和_config.yml文件，注意区分 对本地博客项目做了修改后，需要执行一行命令才会推送到远程仓库上 可在个人Github远程仓库(存放博客项目)的设置下的pages服务中开启https 本文章案例所用的主题为snippet 可根据自己的兴趣增加博客的功能，具体设置在博客项目根目录下的_config.yml和主题根目录下的_config.yml 可根据自己的兴趣修改博客页面 参考资料 Hexo官方文档 snippet nodejs版本的Gitalk/Gitment评论自动初始化","categories":[{"name":"Other","slug":"Other","permalink":"https://sevenhsu.github.io/categories/Other/"}],"tags":[{"name":"HTML","slug":"HTML","permalink":"https://sevenhsu.github.io/tags/HTML/"}],"keywords":[{"name":"Other","slug":"Other","permalink":"https://sevenhsu.github.io/categories/Other/"}]}]}